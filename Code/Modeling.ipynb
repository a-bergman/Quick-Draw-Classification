{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needs to be run once\n",
    "\n",
    "\"\"\"!pip install pycm\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy                 as np\n",
    "import pandas                as pd\n",
    "import matplotlib.pyplot     as plt\n",
    "from pycm                    import ConfusionMatrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics         import balanced_accuracy_score\n",
    "from sklearn.metrics         import classification_report\n",
    "from keras                   import regularizers\n",
    "from keras.models            import Sequential\n",
    "from keras.layers            import Dense, Flatten, Dropout\n",
    "from keras.layers            import Conv2D, MaxPooling2D\n",
    "from keras.utils             import np_utils\n",
    "from IPython.core.display    import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "\n",
    "# Declaring a random state for the modeling process\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Contents\n",
    "     \n",
    " \n",
    "- [Reading In The New Data](#Reading-In-The-New-Data)\n",
    "    - [Data Overview](#Data-Overview)\n",
    "    - [Mapping Labels](#Mapping-Labels)\n",
    "    \n",
    "    \n",
    "- [Preprocessing](#Preprocessing)\n",
    "    - [Declaring X and y](#Declaring-X-and-y)    \n",
    "    - [Train-Test Splitting The Data](#Train-Test-Splitting-The-Data)\n",
    "    - [Reshaping The Data](#Reshaping-The-Data)\n",
    "    \n",
    "    \n",
    "- [Modeling](#Modeling)\n",
    "    - [Setting Up The Neural Network](#Setting-Up-The-Neural-Network)\n",
    "    - [Compiling The Neural Network](#Compiling-The-Neural-Network)\n",
    "    - [Fitting The Training Data](#Fitting-The-Training-Data)\n",
    "    - [Generating Predictions](#Generating-Predictions)\n",
    " \n",
    " \n",
    "- [Evaluation](#Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading In The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading in my credentials\n",
    "\n",
    "with open(\"access_key\", \"r\") as key:\n",
    "    access_key = key.read()\n",
    "    \n",
    "with open(\"secret_key\", \"r\") as secret:\n",
    "    secret_access_key = secret.read()\n",
    "    \n",
    "# Declaring the client as an s3 bucket\n",
    "    \n",
    "client = boto3.client('s3', \n",
    "                      aws_access_key_id     = access_key,\n",
    "                      aws_secret_access_key = secret_access_key)\n",
    "\n",
    "# Naming the bucket and file\n",
    "\n",
    "bucket_name = \"google-quick-draw\"\n",
    "object_key  = \"animals.csv\"\n",
    "\n",
    "# Creating a csv object\n",
    "\n",
    "csv_obj = client.get_object(Bucket = bucket_name, \n",
    "                            Key    = object_key)\n",
    "\n",
    "body = csv_obj['Body']\n",
    "\n",
    "# Reading in the data\n",
    "\n",
    "animals = pd.read_csv(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dimensions of the dataframe\n",
    "\n",
    "animals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the head five rows\n",
    "\n",
    "animals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for null values\n",
    "\n",
    "animals.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals[\"label\"].replace(to_replace = {\"bear\": 0,\n",
    "                                       \"cat\" : 1,\n",
    "                                       \"dog\" : 2},\n",
    "                         inplace    = True)\n",
    "\n",
    "# Making sure the labels are integers\n",
    "\n",
    "animals[\"label\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X variable\n",
    "\n",
    "X = np.array(animals.drop(columns = \"label\")) \n",
    "\n",
    "# y variable\n",
    "\n",
    "y = animals[\"label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Splitting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state = 42, \n",
    "                                                    test_size    = 0.3)\n",
    "\n",
    "# Keeping copies of the originals\n",
    "\n",
    "y_train_org = y_train\n",
    "\n",
    "y_test_org  = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling each X value\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_train /= 255\n",
    "\n",
    "X_test  = X_test.astype(float)\n",
    "X_test  /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the y variables are categorical\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 3)\n",
    "\n",
    "y_test  = np_utils.to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "\n",
    "X_test  = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data type of the train and test sets\n",
    "\n",
    "print(f\"X_train's data type is {type(X_train)}\")\n",
    "\n",
    "print(f\"X_test's data type is {type(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layers\n",
    "\n",
    "# The first convolutional layer\n",
    "\n",
    "cnn.add(Conv2D(filters     = 6,\n",
    "               kernel_size = 3,\n",
    "               activation  = \"relu\",\n",
    "               input_shape = (28,28,1)))\n",
    "\n",
    "# The first maxpooling layer\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# The second convolutional layer\n",
    "\n",
    "cnn.add(Conv2D(128,\n",
    "               kernel_size = 3,\n",
    "               activation  = \"relu\"))\n",
    "\n",
    "# The second maxpooling layer\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layers\n",
    "\n",
    "# Flattening the data\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Adding the first dense layer\n",
    "\n",
    "cnn.add(Dense(128,\n",
    "              activation         = \"relu\",\n",
    "              kernel_regularizer = regularizers.l2(0.0001)))\n",
    "\n",
    "# Adding first dropout\n",
    "\n",
    "cnn.add(Dropout(rate = 0.25))\n",
    "\n",
    "# Adding the second dense layer\n",
    "\n",
    "cnn.add(Dense(64,\n",
    "              activation         = \"relu\",\n",
    "              kernel_regularizer = regularizers.l2(0.0001)))\n",
    "                \n",
    "# Adding second dropout\n",
    "\n",
    "cnn.add(Dropout(rate = 0.25))\n",
    "\n",
    "# Adding the third dense layer\n",
    "\n",
    "cnn.add(Dense(32,\n",
    "              activation         = \"relu\",\n",
    "              kernel_regularizer = regularizers.l2(0.0001)))\n",
    "\n",
    "# Adding second dropout\n",
    "\n",
    "cnn.add(Dropout(rate = 0.25))\n",
    "\n",
    "# Adding the output layer: 3 because there are three classes\n",
    "\n",
    "cnn.add(Dense(3,\n",
    "              activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling The Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss      = \"categorical_crossentropy\",\n",
    "            optimizer = \"adam\",\n",
    "            metrics   = [\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting The Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(X_train,\n",
    "        y_train,\n",
    "        validation_data = (X_train, y_train),\n",
    "        batch_size      = 256,\n",
    "        epochs          = 25,\n",
    "        verbose         = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training predictions\n",
    "\n",
    "train_preds = cnn.predict_classes(X_train,\n",
    "                                  batch_size = 100,\n",
    "                                  verbose    = 0).ravel()\n",
    "\n",
    "# Test predictions\n",
    "\n",
    "test_preds = cnn.predict_classes(X_test,\n",
    "                                 batch_size = 100,\n",
    "                                 verbose    = 0).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(y_train_org, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(y_test_org, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-Of-Contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
